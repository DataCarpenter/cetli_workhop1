{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "- http://joelonsoftware.com/articles/Unicode.html \n",
    "- https://www.youtube.com/watch?v=MijmeoH9LT4\n",
    "- https://www.youtube.com/watch?v=sgHbC6udIqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('Train.csv')\n",
    "sample=pd.read_csv('sample_submission.csv', encoding='utf-8', index_col= 'objectId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What lives inside the train datasets 'product' column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "túró rudi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_product=train['product'][0]\n",
    "print one_product\n",
    "type(one_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we try to decode it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u't\\xfar\\xf3 rudi'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_product.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Althoug the notebook output is a bit crusty, the utf-8 decosed unicode test-representation is the was to go. Here the \"print\" function wil help the reader, and the 'type' shows, that the variable is unicode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "túró rudi\n",
      "<type 'unicode'>\n"
     ]
    }
   ],
   "source": [
    "unicode_one_product= one_product.decode('utf-8')\n",
    "print unicode_one_product\n",
    "print type(unicode_one_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datacarpenter/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_product == unicode_one_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look similar, but because the different type, the equalit returns \"False\". it would be better to throw, an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode character u'\\xfa' in position 1: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-efe699617257>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0municode_one_product\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/datacarpenter/anaconda/lib/python2.7/encodings/utf_8.pyc\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode character u'\\xfa' in position 1: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "unicode_one_product.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This erro shows us the main concerne to keep in mind: Python 2.7 tries to implicitly (secterly)  encode everything into ASCII.  'sys.getdefaultencoding()' shows us why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ascii'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n",
      "<type 'unicode'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_string='alma'\n",
    "u_string=u'alma'\n",
    "print type(simple_string)\n",
    "print type(u_string)\n",
    "simple_string == u_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "altohug they have a differen type 'alma' ans u'alma' happens to be equal. This is considered as a FEATURE by the Py 2.7 developers, but if you happen to have only-unicode chars in your text, it becomes a BUG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_products= train['product'].value_counts().index.tolist()\n",
    "type(all_train_products[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check out our other source file, the sample submission. It contains unicode characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unicode"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sample_products= sample.columns.tolist()\n",
    "type(all_sample_products[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to compare the two lists: how many are different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datacarpenter/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in all_sample_products if not x in all_train_products])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "142 products which are missing?  Try it again with proper types. (unicode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_producst_unicode= [x.decode('utf-8') for x in all_train_products]\n",
    "len([x for x in all_sample_products if not x in all_train_producst_unicode])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Thats better! now we should create a new columns with unicode values in the train table.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_unicode(text):\n",
    "    return text.decode('utf-8')\n",
    "\n",
    "train['product_uni']= train['product'].apply(create_unicode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which equals to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train['product_uni']= train['product'].apply(lambda x: x.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           túró rudi\n",
       "1              zeller\n",
       "2               liszt\n",
       "3             kolbász\n",
       "4                alma\n",
       "5                 tea\n",
       "6              kenyér\n",
       "7            szalvéta\n",
       "8               üdítő\n",
       "9            tusfürdő\n",
       "10           gyümölcs\n",
       "11             zsemle\n",
       "12          ásványvíz\n",
       "13             tejföl\n",
       "14         barnacukor\n",
       "15             öblítő\n",
       "16         darált hús\n",
       "17            fogkrém\n",
       "18              málna\n",
       "19                tej\n",
       "20             öblítő\n",
       "21             kenyér\n",
       "22                tej\n",
       "23                tea\n",
       "24          fokhagyma\n",
       "25          felvágott\n",
       "26                tej\n",
       "27            vajkrém\n",
       "28             dohány\n",
       "29                vaj\n",
       "             ...     \n",
       "22266             tej\n",
       "22267    zsemlemorzsa\n",
       "22268      csirkemell\n",
       "22269         mosópor\n",
       "22270          pékáru\n",
       "22271         paprika\n",
       "22272           kefír\n",
       "22273          uborka\n",
       "22274       zabpehely\n",
       "22275          kenyér\n",
       "22276         narancs\n",
       "22277          tejföl\n",
       "22278         kalcium\n",
       "22279         szalámi\n",
       "22280       felvágott\n",
       "22281            túró\n",
       "22282           szörp\n",
       "22283       fokhagyma\n",
       "22284             tej\n",
       "22285          kenyér\n",
       "22286          tejföl\n",
       "22287       ásványvíz\n",
       "22288         joghurt\n",
       "22289            kávé\n",
       "22290         ketchup\n",
       "22291      savanyúság\n",
       "22292       fokhagyma\n",
       "22293           kefír\n",
       "22294         joghurt\n",
       "22295           üdítő\n",
       "Name: product_uni, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['product_uni']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
